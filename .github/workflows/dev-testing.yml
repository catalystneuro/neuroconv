name: Minimal and Full Tests
on:
  schedule:
    - cron: "0 16 * * *"  # Daily at noon EST
  workflow_call:
    secrets:
      DANDI_API_KEY:
        required: true
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      S3_GIN_BUCKET:
        required: true

env:
  DANDI_API_KEY: ${{ secrets.DANDI_API_KEY }}

jobs:
  run:
    name: Minimal and full tests on ${{ matrix.os }} with Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    steps:
      - uses: s-weigand/setup-conda@v1
      - uses: actions/checkout@v2
      - run: git fetch --prune --unshallow --tags
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      - name: Global Setup
        run: |
          python -m pip install -U pip  # Official recommended way
          pip install pytest-xdist
          git config --global user.email "CI@example.com"
          git config --global user.name "CI Almighty"
          pip install wheel # Needed for scan image



      - name: Install full requirements (-e needed for codecov report)
        run: pip install -e .[full,test]


      - name: Dev gallery - ROIExtractors
        run: pip install git+https://github.com/CatalystNeuro/roiextractors@master
      - name: Dev gallery - PyNWB
        run: pip install git+https://github.com/NeurodataWithoutBorders/pynwb@dev
      - name: Dev gallery - SpikeInterface
        run: pip install git+https://github.com/SpikeInterface/spikeinterface@master
      - name: Dev gallery - NEO
        run: pip install git+https://github.com/NeuralEnsemble/python-neo@master
      - name: Dev gallery - HDMF
        run: pip install git+https://github.com/hdmf-dev/hdmf@dev



      - name: Get ephy_testing_data current head hash
        id: ephys
        run: echo "::set-output name=HASH_EPHY_DATASET::$(git ls-remote https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git HEAD | cut -f1)"
      - name: Cache ephys dataset - ${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
        uses: actions/cache@v2
        id: cache-ephys-datasets
        with:
          path: ./ephy_testing_data
          key: ephys-datasets-2022-08-18-${{ matrix.os }}-${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
      - name: Get ophys_testing_data current head hash
        id: ophys
        run: echo "::set-output name=HASH_OPHYS_DATASET::$(git ls-remote https://gin.g-node.org/CatalystNeuro/ophys_testing_data.git HEAD | cut -f1)"
      - name: Cache ophys dataset - ${{ steps.ophys.outputs.HASH_OPHYS_DATASET }}
        uses: actions/cache@v2
        id: cache-ophys-datasets
        with:
          path: ./ophys_testing_data
          key: ophys-datasets-2022-08-18-${{ matrix.os }}-${{ steps.ophys.outputs.HASH_OPHYS_DATASET }}
      - name: Get behavior_testing_data current head hash
        id: behavior
        run: echo "::set-output name=HASH_BEHAVIOR_DATASET::$(git ls-remote https://gin.g-node.org/CatalystNeuro/behavior_testing_data.git HEAD | cut -f1)"
      - name: Cache behavior dataset - ${{ steps.behavior.outputs.HASH_BEHAVIOR_DATASET }}
        uses: actions/cache@v2
        id: cache-behavior-datasets
        with:
          path: ./behavior_testing_data
          key: behavior-datasets-2022-08-18-${{ matrix.os }}-${{ steps.behavior.outputs.HASH_behavior_DATASET }}



      - if: steps.cache-ephys-datasets.outputs.cache-hit == false || steps.cache-ophys-datasets.outputs.cache-hit == false || steps.cache-behavior-datasets.outputs.cache-hit == false
        name: Install and configure AWS CLI
        run: |
          pip install awscli==1.25.27
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      - if: steps.cache-ephys-datasets.outputs.cache-hit == false
        name: Download ephys dataset from S3
        run: aws s3 cp --recursive ${{ secrets.S3_GIN_BUCKET }}/ephy_testing_data ./ephy_testing_data
      - if: steps.cache-ophys-datasets.outputs.cache-hit == false
        name: Download ophys dataset from S3
        run: aws s3 cp --recursive ${{ secrets.S3_GIN_BUCKET }}/ophys_testing_data ./ophys_testing_data
      - if: steps.cache-behavior-datasets.outputs.cache-hit == false
        name: Download behavior dataset from S3
        run: aws s3 cp --recursive ${{ secrets.S3_GIN_BUCKET }}/behavior_testing_data ./behavior_testing_data



      - name: Run full pytest
        run: pytest -rsx -n auto --dist loadscope
