name: Minimal and Full Tests
on:
  schedule:
    - cron: "0 16 * * *"  # Daily at noon EST
  pull_request:

env:
  DANDI_API_KEY: ${{ secrets.DANDI_API_KEY }}

jobs:
  run:
    name: Minimal and full tests on ${{ matrix.os }} with Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        python-version: [3.7, 3.8, 3.9]
        os: [ubuntu-latest, macos-latest, windows-latest]
    steps:
      - uses: s-weigand/setup-conda@v1
      - uses: actions/checkout@v2
      - run: git fetch --prune --unshallow --tags
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Global Setup
        run: |
          python -m pip install -U pip  # Official recommended way
          pip install pytest-xdist
          git config --global user.email "CI@example.com"
          git config --global user.name "CI Almighty"
          pip install wheel # Needed for scan image
      - name: Install neuroconv with minimal requirements
        run: pip install .[test]
      - name: Run minimal tests
        run: pytest tests/test_internals -n auto --dist loadscope
      - name: Install full requirements (-e needed for codecov report)
        run: pip install -e .[full]



      - name: Get ephy_testing_data current head hash
        id: ephys
        run: echo "::set-output name=HASH_EPHY_DATASET::$(git ls-remote https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git HEAD | cut -f1)"
      - name: Cache ephys dataset - ${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
        uses: actions/cache@v2
        id: cache-ephys-datasets
        with:
          path: ./ephy_testing_data
          key: ephys-datasets-2022-08-18-${{ matrix.os }}-${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
      - name: Get ophys_testing_data current head hash
        id: ophys
        run: echo "::set-output name=HASH_OPHYS_DATASET::$(git ls-remote https://gin.g-node.org/CatalystNeuro/ophys_testing_data.git HEAD | cut -f1)"
      - name: Cache ophys dataset - ${{ steps.ophys.outputs.HASH_OPHYS_DATASET }}
        uses: actions/cache@v2
        id: cache-ophys-datasets
        with:
          path: ./ophys_testing_data
          key: ophys-datasets-2022-08-18-${{ matrix.os }}-${{ steps.ophys.outputs.HASH_OPHYS_DATASET }}
      - name: Get behavior_testing_data current head hash
        id: behavior
        run: echo "::set-output name=HASH_BEHAVIOR_DATASET::$(git ls-remote https://gin.g-node.org/CatalystNeuro/behavior_testing_data.git HEAD | cut -f1)"
      - name: Cache behavior dataset - ${{ steps.behavior.outputs.HASH_BEHAVIOR_DATASET }}
        uses: actions/cache@v2
        id: cache-behavior-datasets
        with:
          path: ./behavior_testing_data
          key: behavior-datasets-2022-08-18-${{ matrix.os }}-${{ steps.behavior.outputs.HASH_behavior_DATASET }}



      - if: steps.cache-ephys-datasets.outputs.cache-hit == false || steps.cache-ophys-datasets.outputs.cache-hit == false || steps.cache-behavior-datasets.outputs.cache-hit == false
        name: Install and configure AWS CLI
        run: |
          pip install awscli==1.25.27
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - if: steps.cache-ephys-datasets.outputs.cache-hit == false
        name: Download ephys dataset from S3
        run: aws s3 cp --recursive ${{ secrets.S3_GIN_BUCKET }}/ephy_testing_data ./ephy_testing_data
      - if: steps.cache-ophys-datasets.outputs.cache-hit == false
        name: Download ophys dataset from S3
        run: aws s3 cp --recursive ${{ secrets.S3_GIN_BUCKET }}/ophys_testing_data ./ophys_testing_data
      - if: steps.cache-behavior-datasets.outputs.cache-hit == false
        name: Download behavior dataset from S3
        run: aws s3 cp --recursive ${{ secrets.S3_GIN_BUCKET }}/behavior_testing_data ./behavior_testing_data



      - name: Run full pytest with coverage
        run: pytest -n auto --dist loadscope --cov=./ --cov-report xml:./codecov.xml
      - if: ${{ matrix.python-version == '3.9' && matrix.os == 'ubuntu-latest'}}
        name: Upload full coverage to Codecov
        uses: codecov/codecov-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./codecov.xml
          flags: unittests
          name: codecov-umbrella
          yml: ./codecov.yml
