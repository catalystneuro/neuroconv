name: Minimal and Full Tests
on:
  schedule:
    - cron: "0 16 * * 1"  # Every Monday at noon EST
  pull_request:  # TODO, swap to manual dispatch

env:
  DANDI_API_KEY: ${{ secrets.DANDI_API_KEY }}

jobs:
  run:
    name: Minimal and full tests on ${{ matrix.os }} with Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix: # Should we perhaps par this down for this gallery? Perhaps only ubuntu-latest with 3.9?
        python-version: [3.7, 3.8, 3.9]
        os: [ubuntu-latest, macos-latest, windows-latest]
        format: [neuroscope]  # can add all the others here
    steps:
      - uses: s-weigand/setup-conda@v1
      - uses: actions/checkout@v2
      - run: git fetch --prune --unshallow --tags
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Global Setup
        run: |
          python -m pip install -U pip  # Official recommended way
          pip install pytest-xdist
          git config --global user.email "CI@example.com"
          git config --global user.name "CI Almighty"
          pip install wheel # Needed for scan image
      - name: Install neuroconv with minimal requirements
        run: pip install .[test]  # Safe to start with this as base for all




      # Only rely on caches in matrix - absolutely no S3 transfer in a matrix this large.
      - name: Get ephy_testing_data current head hash
        id: ephys
        run: echo "::set-output name=HASH_EPHY_DATASET::$(git ls-remote https://gin.g-node.org/NeuralEnsemble/ephy_testing_data.git HEAD | cut -f1)"
      - name: Cache ephys dataset - ${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
        uses: actions/cache@v2
        id: cache-ephys-datasets
        with:
          path: ./ephy_testing_data
          key: ephys-datasets-2022-08-18-${{ matrix.os }}-${{ steps.ephys.outputs.HASH_EPHY_DATASET }}
      - name: Get ophys_testing_data current head hash
        id: ophys
        run: echo "::set-output name=HASH_OPHYS_DATASET::$(git ls-remote https://gin.g-node.org/CatalystNeuro/ophys_testing_data.git HEAD | cut -f1)"
      - name: Cache ophys dataset - ${{ steps.ophys.outputs.HASH_OPHYS_DATASET }}
        uses: actions/cache@v2
        id: cache-ophys-datasets
        with:
          path: ./ophys_testing_data
          key: ophys-datasets-2022-08-18-${{ matrix.os }}-${{ steps.ophys.outputs.HASH_OPHYS_DATASET }}
      - name: Get behavior_testing_data current head hash
        id: behavior
        run: echo "::set-output name=HASH_BEHAVIOR_DATASET::$(git ls-remote https://gin.g-node.org/CatalystNeuro/behavior_testing_data.git HEAD | cut -f1)"
      - name: Cache behavior dataset - ${{ steps.behavior.outputs.HASH_BEHAVIOR_DATASET }}
        uses: actions/cache@v2
        id: cache-behavior-datasets
        with:
          path: ./behavior_testing_data
          key: behavior-datasets-2022-08-18-${{ matrix.os }}-${{ steps.behavior.outputs.HASH_behavior_DATASET }}



      - name: Install a specific format
        run: pip install .[${{ matrix.format }}]
      - name: Run that particular file in the doctest gallery
        run: pytest docs/??? or something
